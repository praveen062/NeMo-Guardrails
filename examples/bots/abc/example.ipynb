{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install redis\n",
    "!pip install pip install nemoguardrails==0.8.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yaml_content = \"\"\"\n",
    "models:\n",
    "- type: main\n",
    "  engine: openai\n",
    "  model: gpt-3.5-turbo\n",
    "  \n",
    "streaming: True\n",
    "  \n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_colang_content = \"\"\"\n",
    "# Defind User Greeting Block\n",
    "define user greeting\n",
    "    \"Hey There!\"\n",
    "    \"How are you?\"\n",
    "    \"What's Up?\"\n",
    "\n",
    "define bot greeting\n",
    "    \"Hello, How can I assist you?\"\n",
    "\n",
    "define flow greeting\n",
    "    user greeting\n",
    "    bot greeting\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"provide api key\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nemoguardrails import RailsConfig, LLMRails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "config = RailsConfig.from_content(rag_colang_content, yaml_content)\n",
    "app = LLMRails(config,llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory.chat_message_histories import RedisChatMessageHistory\n",
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "\n",
    "chat_memory = RedisChatMessageHistory(\n",
    "            url='redis://localhost:6379',\n",
    "            # Your Redis database URL\n",
    "            ttl=600,  # Time to live for the messages in the database\n",
    "            session_id=\"test_session\",\n",
    "            key_prefix='chat_history'\n",
    "        )\n",
    "memory = ConversationBufferWindowMemory(memory_key=\"chat_history\",\n",
    "                                                     chat_memory=chat_memory, k=4,human_prefix='user',ai_prefix='assistant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from langchain_core.messages import HumanMessage\n",
    "def getMessageObj() -> List[dict]:\n",
    "    messages = []\n",
    "    for message in memory.buffer_as_messages:\n",
    "        content = message.content\n",
    "        role = 'assistant'\n",
    "        if type(message) is HumanMessage:\n",
    "            role = 'user'\n",
    "        messages.append({\"role\": role, \"content\": content})\n",
    "    return messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input=\"where is my order\"\n",
    "messages = []\n",
    "messages.append({\"role\": \"context\", \"content\": {'testIntentKey': \"abc\"}})\n",
    "print(f\"history = {getMessageObj()}\")\n",
    "messages.extend(getMessageObj())\n",
    "messages.append({\"role\": \"user\", \"content\": input })\n",
    "output = await app.generate_async(messages=messages)\n",
    "print(f\"the content = {output}\")\n",
    "memory.save_context({\"input\":input},{\"output\":output['content']})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
